var pos = require("parts-of-speech");
var _ = require("lodash");
var natural = require("natural");
var math = require("./math");
var ngrams = natural.NGrams;
var moment = require("moment");
var Lemmer = require("lemmer");
var Dict = require("./dict");
var Utils = require("./utils");
var async = require("async");
var string = require("string");
var debug = require("debug-levels")("SS:Message");

var patchList = function (fullEntities, things) {
  var stopList = ["I"];

  things = things.filter(function (item) {
    return !(stopList.indexOf(item) !== -1);
  });

  for (var i = 0; i < fullEntities.length; i++) {
    for (var j = 0; j < things.length; j++) {
      var thing = things[j];
      if (fullEntities[i].indexOf(thing) > 0) {
        things[j] = fullEntities[i];
      }
    }
  }
  return things;
};

var cleanIncomming = function (message) {
  message = message.replace(/\./g, " ");
  message = message.replace(/\s,\s/g, " ");
  // these used to be bursted but are not anymore.
  message = message.replace(/([a-zA-Z]),\s/g, "$1 ");
  message = message.replace(/"(.*)"/g, "$1");
  message = message.replace(/\s"\s?/g, " ");
  message = message.replace(/\s'\s?/g, " ");
  message = message.replace(/\s?!\s?/g, " ");
  message = message.replace(/\s?!\s?/g, " ");
  return message;
};


// The message could be generated by a repy or raw input
// If it is a reply, we want to save the ID so we can filter them out if said again
var Message = function (msg, options, cb) {
  debug.verbose("Creating message from:", msg);
  var self = this;

  if (!msg) {
    debug.verbose("Callback Early, empty msg");
    return cb({});
  }

  self.id = Utils.genId();

  // If this message is based on a Reply.
  if (options.replyId) {
    self.replyId = options.replyId;
  }

  if (options.clearConvo) {
    self.clearConvo = options.clearConvo;
  }

  self.facts = options.facts;
  self.createdAt = new Date();
  self.raw = cleanIncomming(msg);

  // This version of the message is `EXACTLY AS WRITTEN` by the user
  self.original = options.original;
  self.props = {};


  // self.clean = options.norm.clean(self.raw).trim();
  self.clean = self.raw.trim();
  var wordArray = new pos.Lexer().lex(self.clean);

  // This is where we keep the words
  self.dict = new Dict(wordArray);

  // TODO Phase out words, cwords
  self.words = wordArray;
  self.cwords = math.convertWordsToNumbers(wordArray);
  self.taggedWords = new pos.Tagger().tag(self.cwords);

  var posArray = self.taggedWords.map(function (hash) {
    return hash[1];
  });

  self.lemma(function (err, lemWords) {
    if (err) {
      console.log(err);
    }

    self.lemWords = lemWords;
    var lemString = self.lemWords.join(" ");

    self.lemString = lemString;
    self.posString = posArray.join(" ");

    self.dict.add("num", self.cwords);
    self.dict.add("lemma", self.lemWords);
    self.dict.add("pos", posArray);

    // Classify Question
    self.qtype = options.qtypes.classify(lemString);
    self.qSubType = options.qtypes.questionType(self.raw);
    self.isQuestion = options.qtypes.isQuestion(self.raw);

    self._extendBase();
    self._checkMath();

    // Things are nouns + complex nouns so
    // turkey and french fries would return ['turkey','french fries']
    // this should probably run the list though concepts or something else to validate them more
    // than NN NN etc.
    self.fetchNE(function (entities) {

      var things = self.fetchComplexNouns("nouns");
      var fullEntities = entities.map(function (item) {
        return item.join(" ");
      });

      self.entities = patchList(fullEntities, things);
      self.list = patchList(fullEntities, self.list);

      debug.verbose("Message", self);
      cb(self);
    });
  });
};

Message.prototype._extendBase = function () {
  // Sentence Sentiment
  this.sentiment = 0;

  // Get Nouns and Noun Phrases.
  this.nouns = this.fetchNouns();
  this.names = this.fetchComplexNouns("names");

  // A list of terms
  // this would return an array of thems this are a, b and c;
  // Helpful for choosing something when the qSubType is CH
  this.list = this.fetchList();
  this.adjectives = this.fetchAdjectives();
  this.adverbs = this.fetchAdverbs();
  this.verbs = this.fetchVerbs();
  this.pronouns = this.pnouns = this.fetchProNouns();
  this.compareWords = this.fetchCompareWords();
  this.numbers = this.fetchNumbers();
  this.compare = this.compareWords.length !== 0;
  this.date = this.fetchDate();

  this.names = _.uniq(this.names, function (name) {
    return name.toLowerCase();
  });

  // Nouns with Names removed.
  var t = this.names.map(function (name) {
    return name.toLowerCase();
  });

  this.cNouns = _.filter(this.nouns, function (item) {
    return !_.includes(t, item.toLowerCase());
  });
};

Message.prototype._checkMath = function () {
  var numCount = 0;
  var oppCount = 0;
  var i;

  for (i = 0; i < this.taggedWords.length; i++) {
    if (this.taggedWords[i][1] === "CD") {
      numCount++;
    }
    if (this.taggedWords[i][1] === "SYM" ||
      math.mathTerms.indexOf(this.taggedWords[i][0]) !== -1) {
      // Half is a number and not an opp
      if (this.taggedWords[i][0] === "half") {
        numCount++;
      } else {
        oppCount++;
      }
    }
  }

  // Augment the Qtype for Math Expressions
  this.numericExp = numCount >= 2 && oppCount >= 1 ? true : false;
  this.halfNumericExp = numCount === 1 && oppCount === 1 ? true : false;

  if (this.numericExp || this.halfNumericExp) {
    this.qtype = "NUM:expression";
    this.isQuestion = true;
  }

};

Message.prototype.fetchCompareWords = function () {
  return this.dict.fetch("pos", ["JJR", "RBR"]);
};

Message.prototype.fetchAdjectives = function () {
  return this.dict.fetch("pos", ["JJ", "JJR", "JJS"]);
};

Message.prototype.fetchAdverbs = function () {
  return this.dict.fetch("pos", ["RB", "RBR", "RBS"]);
};

Message.prototype.fetchNumbers = function () {
  return this.dict.fetch("pos", ["CD"]);
};

Message.prototype.fetchVerbs = function () {
  return this.dict.fetch("pos", ["VB", "VBN", "VBD", "VBZ", "VBP", "VBG"]);
};

Message.prototype.fetchProNouns = function () {
  return this.dict.fetch("pos", ["PRP", "PRP$"]);
};


// TODO - Move this to utils
var pennToWordnet = function (pennTag) {
  if (string(pennTag).startsWith("J")) {
    return "a";
  } else if (string(pennTag).startsWith("V")) {
    return "v";
  } else if (string(pennTag).startsWith("N")) {
    return "n";
  } else if (string(pennTag).startsWith("R")) {
    return "r";
  } else {
    return null;
  }
};

// We only want to lemmatize the nouns, verbs, adverbs and adjectives.
Message.prototype.lemma = function (callback) {

  var itor = function (hash, next) {
    var word = hash[0].toLowerCase();
    var tag = pennToWordnet(hash[1]);

    // console.log(word, tag);
    // next(null, [word]);

    if (tag) {
      try {
        Lemmer.lemmatize(word + "#" + tag, next);
      } catch (e) {
        console.log("Caught in Excption", e);
        // This is probably because it isn't an english word.
        next(null, [word]);
      }
    } else {
      // Some words don't have a tag ie: like, to.
      next(null, [word]);
    }
  };

  async.map(this.taggedWords, itor, function (err, transformed) {
    var res = _.map(_.flatten(transformed), function (a) {
      return a.split("#")[0];
    });
    callback(err, res);
  });
};

Message.prototype.fetchNouns = function () {
  return this.dict.fetch("pos", ["NN", "NNS", "NNP", "NNPS"]);
};

// Fetch list looks for a list of items
// a or b
// a, b or c
Message.prototype.fetchList = function () {
  debug.verbose("Fetch List");
  var self = this;
  var l = [];
  if (/NNP? CC(?:\s*DT\s|\s)NNP?/.test(self.posString) ||
      /NNP? , NNP?/.test(self.posString) ||
      /NNP? CC(?:\s*DT\s|\s)JJ NNP?/.test(self.posString)) {
    var sn = false;
    for (var i = 0; i < self.taggedWords.length; i++) {
      if (self.taggedWords[i + 1] &&
        (self.taggedWords[i + 1][1] === "," ||
        self.taggedWords[i + 1][1] === "CC" ||
        self.taggedWords[i + 1][1] === "JJ")) {
        sn = true;
      }
      if (self.taggedWords[i + 1] === undefined) {
        sn = true;
      }
      if (sn === true && Utils._isTag(self.taggedWords[i][1], "nouns")) {
        l.push(self.taggedWords[i][0]);
        sn = false;
      }
    }
  }
  return l;
};

Message.prototype.fetchDate = function () {
  var self = this;
  var date = null;
  var months = ["january", "february", "march",
    "april", "may", "june", "july", "august", "september",
    "october", "november", "december"];

  // http://rubular.com/r/SAw0nUqHJh
  var re = /([a-z]{3,10}\s+[\d]{1,2}\s?,?\s+[\d]{2,4}|[\d]{2}\/[\d]{2}\/[\d]{2,4})/i;

  if (self.clean.match(re)) {
    var m = self.clean.match(re);
    debug.verbose("Date", m);
    date = moment(Date.parse(m[0]));
  }

  if (self.qtype === "NUM:date" && date === null) {
    debug.verbose("Try to resolve Date");
    // TODO, in x months, x months ago, x months from now
    if (_.includes(self.nouns, "month")) {
      if (self.dict.includes("next")) {
        date = moment().add("M", 1);
      }
      if (self.dict.includes("last")) {
        date = moment().subtract("M", 1);
      }
    } else if (Utils.inArray(self.nouns, months)) {
      // IN month vs ON month
      var p = Utils.inArray(self.nouns, months);
      date = moment(self.nouns[p] + " 1", "MMM D");
    }
  }

  return date;
};

// Fetch Named Entities.
// Pulls concepts from the bigram DB.
Message.prototype.fetchNE = function (callback) {
  var self = this;
  var bigrams = ngrams.bigrams(this.taggedWords);

  var sentencebigrams = _.map(bigrams, function (bigram) {
    return _.map(bigram, function (item) {
      return item[0];
    });
  });

  var itor = function (item, cb) {
    var bigramLookup = {subject: item.join(" "), predicate: "isa", object: "bigram" };
    self.facts.db.get(bigramLookup, function (err, res) {
      if (err) {
        debug.error(err);
      }

      if (!_.isEmpty(res)) {
        cb(true);
      } else {
        cb();
      }
    });
  };

  async.filter(sentencebigrams, itor, function (res) {
    callback(res);
  });
};

// This function will return proper nouns and group them together if they need be.
// This function will also return regular nonus or common nouns grouped as well.
// Rob Ellis and Brock returns ['Rob Ellis', 'Brock']
// @tags - Array, Words with POS [[word, pos], [word, pos]]
// @lookupType String, "nouns" or "names"
Message.prototype.fetchComplexNouns = function (lookupType) {
  var tags = this.taggedWords;
  var bigrams = ngrams.bigrams(tags);
  var nouns;
  var tester;

  if (lookupType === "names") {
    tester = function (item) {
      return item[1] === "NNP" || item[1] === "NNPS";
    };
  } else {
    tester = function (item) {
      return item[1] === "NN" || item[1] === "NNS" || item[1] === "NNP" || item[1] === "NNPS";
    };
  }
  nouns = _.filter(_.map(tags, function (item) {
    return tester(item) ? item[0] : null;
  }), Boolean);

  var nounBigrams = ngrams.bigrams(nouns);

  // Get a list of term
  var neTest = _.map(bigrams, function (bigram) {
    return _.map(bigram, function (item) {
      return tester(item);
    });
  });

  // Return full names from the list
  var fullnames = _.map(_.filter(_.map(neTest, function (item, key) {
    return _.every(item, _.identity) ? bigrams[key] : null; }), Boolean),
    function (item) {
      return (_.map(item, function (item2) {
        return item2[0];
      })).join(" ");
    }
  );

  debug.verbose("fullnames", lookupType, fullnames);

  var x = _.map(nounBigrams, function (item) {
    return _.includes(fullnames, item.join(" "));
  });

  // Filter X out of the bigrams or names?
  _.filter(nounBigrams, function (item, key) {
    if (x[key]) {
      // Remove these from the names
      nouns.splice(nouns.indexOf(item[0]), 1);
      nouns.splice(nouns.indexOf(item[1]), 1);
      return nouns;
    }
  });

  return nouns.concat(fullnames);
};

module.exports = Message;
